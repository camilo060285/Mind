# Mind LLM Configuration - Local setup
# This enables phi-based semi-autonomous operation without cloud dependencies

MIND_LLM_PROVIDER=llama_cpp
MIND_LLM_MODEL=phi
MIND_LLAMA_BIN=/home/cris_agent_admin/llama.cpp/build/bin/llama-completion
MIND_MODELS_DIR=/home/cris_agent_admin/local_llms/models
